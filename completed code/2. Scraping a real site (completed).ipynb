{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Gathering some reactor data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules to facilitate the scrape\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch HTML with `requests`\n",
    "\n",
    "`requests` is great at playing web browser. For more information, check out the [full documentation](http://docs.python-requests.org/en/master/).\n",
    "\n",
    "```python\n",
    "requests.get('some URL')\n",
    "# navigates to a site and sends you the response\n",
    "\n",
    "response.content\n",
    "# a way requests serves up the page's HTML source code\n",
    "```\n",
    "\n",
    "We are going to be getting data on nuclear reactors operating in the U.S.: http://www.nrc.gov/reactors/operating/list-power-reactor-units.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fetch the contents of webpage with requests\n",
    "url = \"http://www.nrc.gov/reactors/operating/list-power-reactor-units.html\"\n",
    "main_page = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse HTML with `BeautifulSoup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let BeautifulSoup parse the content of that page\n",
    "soup = BeautifulSoup(main_page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# snip out the table and pass it to a new variable\n",
    "reactors_table = soup.find('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print reactor_table to verify we have the right thing\n",
    "print(reactors_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use .find_all to create a list of rows in the table\n",
    "reactor_rows = reactors_table.find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate the fourth row and print it\n",
    "ex_row = reactor_rows[3]\n",
    "print(ex_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of our table's rows, with a little shading and indentation:\n",
    "\n",
    "```html\n",
    "<tr valign=\"top\">\n",
    "    <td scope=\"row\"><a href=\"/info-finder/reactors/ano1.html\">Arkansas Nuclear 1</a><br/>05000313</td>\n",
    "    <td align=\"center\">DPR-51</td>\n",
    "    <td>PWR</td>\n",
    "    <td>6 miles WNW of Russellville,  AR</td>\n",
    "    <td>Entergy Nuclear Operations, Inc.</td>\n",
    "    <td align=\"middle\">4</td>\n",
    "</tr>```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .find_all again to generate a list of the row's cells and return it\n",
    "cells = ex_row.find_all('td')\n",
    "cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BeautifulSoup has a couple other methods we haven't discussed yet that are helpful for extracting the information _inside_ of tags:\n",
    "```python\n",
    "soup.contents\n",
    "# breaks up everything in a tag into a fresh list (useful when you have more than text in a cell)\n",
    "\n",
    "soup.get('some attribute')\n",
    "# returns the attribute (useful for getting URLs from <a> tags, for example)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the \"contents\" of the first item in cells\n",
    "cells[0].contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate and print the name, the link and the docket number\n",
    "print(cells[0].contents[0].text)\n",
    "print(cells[0].contents[0].get('href'))\n",
    "print(cells[0].contents[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make an empty list to hold the data\n",
    "scraped_data = []\n",
    "\n",
    "# a for loop is going to take us through every row in the table EXCEPT the header\n",
    "# combining two steps: the list it pulls from will be greated by a .find_all for 'tr' tags\n",
    "for row in reactors_table.find_all('tr')[1:]:\n",
    "    \n",
    "    # .find_all 'td' tags in the row and put them into a variable\n",
    "    cells = row.find_all('td')\n",
    "    \n",
    "    # extract the cell contents\n",
    "    reactor_name = cells[0].contents[0].text\n",
    "    link = 'http://www.nrc.gov' + cells[0].contents[0].get('href')\n",
    "    docket = cells[0].contents[2]\n",
    "    license = cells[1].text\n",
    "    reactor_type = cells[2].text\n",
    "    location = cells[3].text\n",
    "    owner = cells[4].text\n",
    "    region = cells[5].text\n",
    "    \n",
    "    # append the collected data to the empty list\n",
    "    scraped_data.append([reactor_name, link, docket, license, reactor_type, location, owner, region])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# open a file and write our data to it\n",
    "with open('reactor_data.csv', 'w') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(['reactor_name', 'link', 'docket', 'license', 'reactor_type', 'location', 'owner', 'region'])\n",
    "    writer.writerows(scraped_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you want only a simple HTML table on a page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_html('https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population', header=0)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more on pandas and parsing tabular data, I recommend the CAR class and/or [this book](http://shop.oreilly.com/product/0636920023784.do)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
